{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOR1Mti/e7UjWiiPuqMDTA2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Biblioteca"],"metadata":{"id":"kvJGTYgEyj3h"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nuUhP3tySjG"},"outputs":[],"source":["!pip install mne\n","!pip install mne_bids\n","!pip install openneuro-py\n","!pip install dash\n","!pip install dash-bootstrap-components\n","!pip install captum\n","import openneuro\n","from mne_bids import BIDSPath, read_raw_bids\n","import os\n","from mne.datasets import sample\n","from mne.preprocessing import ICA\n","from mne.channels import make_standard_montage\n","import matplotlib.pyplot as plt\n","from mne.datasets import sample\n","import pandas as pd\n","import seaborn as sns\n","import openneuro\n","import numpy as np\n","from numpy.fft import fft, ifft, fftfreq\n","from mne import make_fixed_length_epochs\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.optim as optim\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from captum.attr import IntegratedGradients\n"]},{"cell_type":"markdown","source":["## Banco de dados"],"metadata":{"id":"Eb-MQu9GyoGM"}},{"cell_type":"code","source":["\n","# Definir o ID do dataset\n","dataset = \"ds002778\"\n","\n","# Definir o diretório onde o dataset será salvo\n","bids_root = os.path.join(os.path.dirname(sample.data_path()), dataset)\n","\n","# Criar o diretório, se ele ainda não existir\n","if not os.path.isdir(bids_root):\n","    os.makedirs(bids_root)\n","\n","# Baixar todos os dados do dataset\n","openneuro.download(dataset=dataset, target_dir=bids_root)"],"metadata":{"id":"BIs5uisCytA0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Diretório base dos dados no formato BIDS\n","bids_root = '/root/mne_data/ds002778'\n","\n","# Lista para armazenar os dados carregados\n","eeg_data = {}\n","\n","# Iterar pelos participantes\n","for participant_id in os.listdir(bids_root):\n","    if participant_id.startswith(\"sub-\"):  # Apenas participantes\n","        print(f\"Carregando dados para {participant_id}...\")\n","\n","        participant_dir = os.path.join(bids_root, participant_id)\n","        sessions = os.listdir(participant_dir)\n","        print(f\"  Sessões disponíveis: {sessions}\")\n","\n","        try:\n","            # Verificar o tipo de participante: Grupo Controle (HC) ou Parkinson (PD)\n","            if \"ses-hc\" in sessions:  # Grupo Controle\n","                bids_path_hc = BIDSPath(root=bids_root, subject=participant_id.replace(\"sub-\", \"\"),\n","                                        session=\"hc\", task=\"rest\", datatype=\"eeg\", extension=\".bdf\")\n","                print(f\"  Tentando carregar: {bids_path_hc}\")\n","                if bids_path_hc.fpath.exists():\n","                    raw_hc = read_raw_bids(bids_path_hc)\n","                    eeg_data[f\"{participant_id}_hc\"] = raw_hc\n","                    print(f\"  Dados carregados para {participant_id} - HC.\")\n","                else:\n","                    print(f\"  Arquivo não encontrado para {participant_id} - HC.\")\n","\n","            elif \"ses-on\" in sessions and \"ses-off\" in sessions:  # Grupo Parkinson\n","                # Carregar estado OFF\n","                bids_path_off = BIDSPath(root=bids_root, subject=participant_id.replace(\"sub-\", \"\"),\n","                                         session=\"off\", task=\"rest\", datatype=\"eeg\", extension=\".bdf\")\n","                print(f\"  Tentando carregar: {bids_path_off}\")\n","                if bids_path_off.fpath.exists():\n","                    raw_off = read_raw_bids(bids_path_off)\n","                    eeg_data[f\"{participant_id}_off\"] = raw_off\n","                    print(f\"  Dados carregados para {participant_id} - OFF.\")\n","                else:\n","                    print(f\"  Arquivo não encontrado para {participant_id} - OFF.\")\n","\n","                # Carregar estado ON\n","                bids_path_on = BIDSPath(root=bids_root, subject=participant_id.replace(\"sub-\", \"\"),\n","                                        session=\"on\", task=\"rest\", datatype=\"eeg\", extension=\".bdf\")\n","                print(f\"  Tentando carregar: {bids_path_on}\")\n","                if bids_path_on.fpath.exists():\n","                    raw_on = read_raw_bids(bids_path_on)\n","                    eeg_data[f\"{participant_id}_on\"] = raw_on\n","                    print(f\"  Dados carregados para {participant_id} - ON.\")\n","                else:\n","                    print(f\"  Arquivo não encontrado para {participant_id} - ON.\")\n","\n","        except Exception as e:\n","            print(f\"Erro ao carregar dados para {participant_id}: {str(e)}\")\n","\n","print(f\"Carregamento de dados concluído! Total de participantes carregados: {len(eeg_data)}\")\n"],"metadata":{"id":"lBnyZ_WLzUon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extrair IDs únicos dos pacientes\n","unique_patients = set(participant.split(\"_\")[0] for participant in eeg_data.keys())\n","\n","# Contar o número total de pacientes únicos\n","total_unique_patients = len(unique_patients)\n","\n","# Exibir os IDs únicos e o número total de pacientes únicos\n","print(\"Pacientes únicos carregados:\")\n","for patient in unique_patients:\n","    print(patient)\n","print(f\"\\nTotal de pacientes únicos: {total_unique_patients}\")"],"metadata":{"id":"kA64a2hkzYKE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pré-processamento\n"],"metadata":{"id":"88rxFzKZzTj0"}},{"cell_type":"markdown","source":["#### Aplicar filtro Notch para remover ruídos de linha elétrica."],"metadata":{"id":"tUSKrkLPzlFL"}},{"cell_type":"code","source":["# Frequências para o filtro Notch (60 Hz e 120 Hz)\n","notch_freqs = [60, 120]\n","\n","# Iterar pelos dados carregados\n","for participant, raw_data in eeg_data.items():\n","    try:\n","        print(f\"Carregando dados para {participant} na memória...\")\n","        raw_data.load_data()  # Carregar dados na memória\n","\n","        print(f\"Aplicando filtro Notch para {participant}...\")\n","        raw_notch = raw_data.notch_filter(freqs=notch_freqs)\n","        eeg_data[participant] = raw_notch  # Atualizar os dados no dicionário\n","\n","        print(f\"Filtro Notch aplicado para {participant}.\")\n","    except Exception as e:\n","        print(f\"Erro ao aplicar filtro Notch para {participant}: {e}\")\n","\n","print(\"Filtro Notch aplicado a todos os participantes.\")\n"],"metadata":{"id":"79d4djaqzpnS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Passa-Banda"],"metadata":{"id":"_mKvf7qAzvCc"}},{"cell_type":"code","source":["# Definir os limites do filtro passa-banda\n","low_freq = 0.5  # Limite inferior\n","high_freq = 50  # Limite superior\n","\n","# Aplicar o filtro para cada conjunto de dados\n","for participant_id, raw_data in eeg_data.items():\n","    try:\n","        print(f\"Aplicando filtro passa-banda ({low_freq}-{high_freq} Hz) para {participant_id}...\")\n","\n","        # Certificar-se de que os dados estão na memória\n","        raw_data.load_data()\n","\n","        # Aplicar o filtro passa-banda\n","        raw_filtered = raw_data.filter(l_freq=low_freq, h_freq=high_freq)\n","\n","        # Substituir os dados antigos pelos filtrados no dicionário\n","        eeg_data[participant_id] = raw_filtered\n","        print(f\"Filtro passa-banda aplicado para {participant_id}.\")\n","\n","    except Exception as e:\n","        print(f\"Erro ao aplicar filtro passa-banda para {participant_id}: {e}\")\n","\n","print(\"Filtro passa-banda aplicado a todos os participantes.\")"],"metadata":{"id":"v3a0E8ICz0St"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Verificação dos Dados Pós-Filtro"],"metadata":{"id":"RSl6RY_x0hgt"}},{"cell_type":"code","source":["\n","\n","# Diretório temporário para salvar os gráficos\n","output_dir = \"/mnt/data/output_graphics\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Função para verificar o sinal e a PSD e salvar os gráficos\n","def verificar_sinal_psd_salvar(raw_data, title, save_path):\n","    # Garantir que o diretório de salvamento existe\n","    os.makedirs(save_path, exist_ok=True)\n","\n","    # Visualizar e salvar o sinal de EEG\n","    signal_path = os.path.join(save_path, f\"{title.replace(' ', '_')}_signal.png\")\n","    plt.figure(figsize=(15, 5))\n","    raw_data.plot(start=0, duration=10, n_channels=10, title=title, show=False)\n","    plt.savefig(signal_path, dpi=300)\n","    plt.close()\n","\n","    # Visualizar e salvar a PSD\n","    psd_path = os.path.join(save_path, f\"{title.replace(' ', '_')}_psd.png\")\n","    plt.figure(figsize=(10, 5))\n","    raw_data.plot_psd(fmin=0.5, fmax=50, average=True, show=False)\n","    plt.title(f\"PSD: {title}\")\n","    plt.savefig(psd_path, dpi=300)\n","    plt.close()\n","\n","    return signal_path, psd_path\n","\n","# Simulação de estrutura de `eeg_data` e exemplo de uso\n","try:\n","\n","    # Criar um dicionário para análise\n","    samples = {\n","        \"PD_OFF - sub-pd17_off\": eeg_data[\"sub-pd17_off\"],\n","        \"PD_ON - sub-pd17_on\": eeg_data[\"sub-pd17_on\"],\n","        \"HC - sub-hc24_hc\": eeg_data[\"sub-hc24_hc\"]\n","    }\n","\n","    # Verificar os dados e salvar gráficos\n","    saved_files = []\n","    for group, raw in samples.items():\n","        print(f\"Salvando gráficos para {group}...\")\n","        files = verificar_sinal_psd_salvar(raw, f\"Sinal e PSD - {group}\", save_path=output_dir)\n","        saved_files.extend(files)\n","\n","    print(\"Gráficos salvos nos seguintes arquivos:\")\n","    for file in saved_files:\n","        print(file)\n","\n","except Exception as e:\n","    print(f\"Erro ao processar os dados: {e}\")"],"metadata":{"id":"HnttfWzi0mcH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Remoção de artefatos"],"metadata":{"id":"Hn2a6E900Ovf"}},{"cell_type":"code","source":["\n","\n","# Configuração geral de ICA e salvamento dos gráficos\n","def aplicar_ica_e_salvar_graficos(eeg_data, channels_to_remove, output_dir, montage_type=\"standard_1020\"):\n","    dados_limpos = {}\n","    montage = make_standard_montage(montage_type)  # Configurar montagem padrão\n","\n","    # Criar diretório de saída, se não existir\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for participant_id, raw_data in eeg_data.items():\n","        try:\n","            print(f\"Iniciando ICA para {participant_id}...\")\n","\n","            # Verificar e remover canais específicos\n","            raw_data.drop_channels([ch for ch in channels_to_remove if ch in raw_data.info['ch_names']])\n","\n","            # Aplicar montagem e carregar dados na memória\n","            raw_data.set_montage(montage)\n","            raw_data.load_data()\n","\n","            # Configurar ICA\n","            ica = ICA(n_components=20, random_state=42, max_iter='auto')\n","\n","            # Ajustar ICA aos dados filtrados\n","            print(f\"Ajustando ICA para {participant_id}...\")\n","            ica.fit(raw_data.copy().pick_types(eeg=True))\n","\n","            # Identificar artefatos relacionados a EOG usando o canal frontal (Fp1)\n","            print(f\"Identificando artefatos relacionados a EOG para {participant_id}...\")\n","            eog_indices, eog_scores = ica.find_bads_eog(raw_data, ch_name='Fp1')\n","\n","            # Exibir os índices dos componentes relacionados a EOG\n","            print(f\"Componentes relacionados a EOG para {participant_id}: {eog_indices}\")\n","\n","            # Marcar os componentes identificados para exclusão\n","            ica.exclude = eog_indices\n","\n","            # Aplicar ICA para limpar os dados\n","            print(f\"Aplicando ICA para limpar os dados de {participant_id}...\")\n","            raw_cleaned = ica.apply(raw_data.copy())\n","\n","            # Adicionar dados limpos ao dicionário\n","            dados_limpos[participant_id] = raw_cleaned\n","\n","            # Criar diretório específico para o participante\n","            participant_dir = os.path.join(output_dir, participant_id)\n","            os.makedirs(participant_dir, exist_ok=True)\n","\n","            # Salvar o gráfico dos componentes ICA\n","            plot_path = os.path.join(participant_dir, f\"{participant_id}_ica_components.png\")\n","            print(f\"Salvando gráfico de componentes ICA para {participant_id} em {plot_path}...\")\n","            ica.plot_components(show=False)\n","            plt.savefig(plot_path)\n","            plt.close()\n","\n","            print(f\"ICA aplicada e gráfico salvo com sucesso para {participant_id}.\\n\")\n","        except Exception as e:\n","            print(f\"Erro ao processar {participant_id}: {e}\")\n","\n","    return dados_limpos\n","\n","# Lista de canais a serem removidos\n","channels_to_remove = ['EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status']\n","\n","# Diretório para salvar os gráficos\n","output_dir = \"/mnt/data/ica_plots\"\n","\n","# Aplicar ICA para todos os participantes e salvar gráficos\n","dados_limpos = aplicar_ica_e_salvar_graficos(eeg_data, channels_to_remove, output_dir)"],"metadata":{"id":"F97XG_Ro0WX_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Identificar os dados limpos para cada condição\n","psd_on = dados_limpos.get(\"sub-pd9_on\")   # Substitua por identificador correto para condição ON\n","psd_off = dados_limpos.get(\"sub-pd9_off\") # Substitua por identificador correto para condição OFF\n","psd_hc = dados_limpos.get(\"sub-hc31_hc\")  # Substitua por identificador correto para HC\n","\n","# Verificar se os dados estão disponíveis\n","dados_psd = {\n","    \"on\": psd_on,\n","    \"off\": psd_off,\n","    \"hc\": psd_hc\n","}\n","\n","# Iterar pelas condições e calcular o PSD\n","for condition, dados  in dados_psd.items():\n","    if dados is not None:\n","        try:\n","            print(f\"Calculando PSD para a condição {condition}...\")\n","\n","            # Calcular o PSD (com limites de frequência ajustados)\n","            psd = dados.copy().pick_types(eeg=True).compute_psd(fmin=0.5, fmax=50.0)\n","\n","            # Plotar o PSD\n","            plt.clf()  # Limpar gráficos anteriores\n","            psd.plot()\n","\n","            # Melhorar o título\n","            plt.suptitle(f\"Densidade Espectral de Potência (PSD) - Condição {condition.upper()}\",\n","                         fontsize=16,\n","                         fontweight='bold',\n","                         y=1.05)  # Centralizado e ajustado acima do gráfico\n","\n","            plt.show()\n","\n","        except Exception as e:\n","            print(f\"Erro ao calcular ou plotar o PSD para {condition}: {e}\")\n","    else:\n","        print(f\"Dados para a condição '{condition}' não encontrados. Certifique-se de que os dados estão disponíveis.\")"],"metadata":{"id":"gxaJZG4U5wDK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Normalização dos dados limpos"],"metadata":{"id":"eI-s-qZW5dDY"}},{"cell_type":"code","source":["# Função para normalizar os dados (Z-score normalization)\n","def z_score_normalization(data):\n","\n","\n","    mean = np.mean(data, axis=1, keepdims=True)  # Média por canal\n","    std = np.std(data, axis=1, keepdims=True)    # Desvio padrão por canal\n","    return (data - mean) / std\n","\n","# Aplicar normalização aos dados limpos\n","dados_normalizados = {}\n","for participant_id, raw_cleaned in dados_limpos.items():\n","    data = raw_cleaned.get_data()  # Extrair os dados em formato de array [n_channels, n_samples]\n","    normalized_data = z_score_normalization(data)  # Normalizar os dados\n","    dados_normalizados[participant_id] = normalized_data  # Armazenar os dados normalizados\n","\n","    print(f\"Normalização aplicada para {participant_id}. Dimensões: {normalized_data.shape}\")\n"],"metadata":{"id":"s4E9CCX556Uf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Segmentação"],"metadata":{"id":"F7bUoC0c5veC"}},{"cell_type":"code","source":["# Parâmetros de segmentação\n","segment_duration = 2.0  # Duração de cada segmento em segundos\n","overlap = 0.2    # Proporção de sobreposição (exemplo: 50%)\n","sfreq = 256  # Frequência de amostragem (ajuste para os seus dados)\n","\n","# Função para realizar a segmentação\n","def segmentar_dados(data, sfreq, segment_duration, overlap):\n","    n_channels, n_samples = data.shape\n","    segment_length = int(segment_duration * sfreq)  # Comprimento de cada segmento em pontos\n","    step = int(segment_length * (1 - overlap))      # Passo entre segmentos\n","\n","    # Validação do parâmetro 'step'\n","    if step <= 0:\n","        raise ValueError(\"O parâmetro 'overlap' deve ser menor que 1.0.\")\n","\n","    segments = []\n","    for start in range(0, n_samples - segment_length + 1, step):\n","        end = start + segment_length\n","        segments.append(data[:, start:end])\n","\n","    # Incluir o último segmento, se necessário\n","    if n_samples % step != 0 and (n_samples - segment_length) % step != 0:\n","        segments.append(data[:, -segment_length:])\n","\n","    return np.array(segments)  # [n_segments, n_channels, n_samples_per_segment]\n","\n","# Aplicar segmentação aos dados normalizados\n","dados_segmentados = {}\n","for participant_id, normalized_data in dados_normalizados.items():\n","    try:\n","        segmentos = segmentar_dados(normalized_data, sfreq, segment_duration, overlap)\n","        dados_segmentados[participant_id] = segmentos  # Armazenar os segmentos\n","        print(f\"Segmentação concluída para {participant_id}. Segmentos: {segmentos.shape}\")\n","    except Exception as e:\n","        print(f\"Erro ao processar {participant_id}: {e}\")"],"metadata":{"id":"Hb_eL81U6Hi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Nomes reais dos canais (já obtidos de raw.info['ch_names'])\n","nomes_canais = [\n","    'Fp1', 'AF3', 'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5',\n","    'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8',\n","    'CP6', 'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2',\n","    'Fz', 'Cz'\n","]\n","\n","# Exemplo de estrutura de pacientes\n","pacientes = {\n","    \"ON\": dados_segmentados[\"sub-pd6_on\"],  # Substitua com seus dados reais\n","    \"OFF\": dados_segmentados[\"sub-pd6_off\"],  # Substitua com seus dados reais\n","    \"HC\": dados_segmentados[\"sub-hc10_hc\"]  # Substitua com seus dados reais\n","}\n","\n","# Ajustando para visualizar todos os canais e mais segmentos\n","n_canais = len(nomes_canais)  # Total de canais disponíveis no arquivo\n","n_segmentos = 1  # Visualizar apenas 1 segmento por classe\n","\n","# Criar o gráfico novamente\n","fig, axes = plt.subplots(n_segmentos, len(pacientes), figsize=(15, 15), sharex=True, sharey=True)\n","\n","# Garantir que `axes` seja uma matriz bidimensional mesmo com 1 segmento\n","if n_segmentos == 1:\n","    axes = np.expand_dims(axes, axis=0)\n","\n","for col, (classe, segmentos) in enumerate(pacientes.items()):\n","    for row in range(n_segmentos):\n","        # Selecionar o segmento\n","        segmento = segmentos[row, :n_canais, :]  # Seleciona os canais e amostras do segmento\n","\n","        # Criar vetor de tempo\n","        tempo = np.linspace(0, segmento.shape[1] / sfreq, segmento.shape[1])\n","\n","        # Plotar cada canal do segmento\n","        for canal in range(segmento.shape[0]):\n","            axes[row, col].plot(tempo, segmento[canal, :] + canal * 10, label=nomes_canais[canal])  # Deslocamento para visualização\n","\n","        # Ajustar título e eixos\n","        axes[row, col].set_title(f\"{classe} - Segmento {row + 1}\")\n","        axes[row, col].set_xlabel(\"Tempo (s)\")\n","        axes[row, col].set_ylabel(\"Amplitude (μV)\")\n","\n","        # Adicionar legenda apenas no primeiro segmento de cada classe\n","        if row == 0:\n","            axes[row, col].legend(loc=\"upper right\", fontsize=8)\n","\n","# Ajustar layout e salvar a figura\n","fig.suptitle(\"Segmentos dos Canais de EEG (ON, OFF, HC)\", fontsize=16)\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","# Salvar a figura\n","fig_path = \"/mnt/data/segmentos_eeg_reais_raw.png\"\n","plt.savefig(fig_path, dpi=300)  # Salvar com alta qualidade\n","plt.show()\n","\n","# Informar o caminho do arquivo salvo\n","print(f\"Figura salva em: {fig_path}\")\n","\n","\n"],"metadata":{"id":"hdagW0ml6OU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_dir = \"segmentos_plotados\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Plotar e salvar gráficos dos segmentos\n","for participant_id, segments in dados_segmentados.items():\n","    print(f\"Plotando segmentos para {participant_id}...\")\n","    num_segments = min(3, segments.shape[0])  # Mostrar até 3 segmentos\n","    for i in range(num_segments):\n","        plt.figure(figsize=(10, 4))\n","        plt.plot(segments[i, 0, :])  # Plotar apenas o primeiro canal\n","        plt.title(f\"{participant_id} - Segmento {i+1}\")\n","        plt.xlabel(\"Tempo (amostras)\")\n","        plt.ylabel(\"Amplitude\")\n","        plt.grid(True)\n","        # Salvar o gráfico\n","        output_path = os.path.join(output_dir, f\"{participant_id}_segmento_{i+1}.png\")\n","        plt.savefig(output_path)\n","        plt.close()\n","        print(f\"Gráfico salvo em: {output_path}\")\n"],"metadata":{"id":"1XyblTTxHHVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Treino e Teste"],"metadata":{"id":"u4BoQZ2O53cR"}},{"cell_type":"code","source":["# Configurar o dispositivo (GPU ou CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Usando dispositivo: {device}\")\n","\n","# Função para combinar dados e rótulos para HC, OFF e ON\n","def preparar_dados_segmentados(dados_segmentados):\n","    X = []\n","    y = []\n","    for participant_id, segmentos in dados_segmentados.items():\n","        if \"hc\" in participant_id:\n","            label = 0  # HC\n","        elif \"off\" in participant_id:\n","            label = 1  # OFF\n","        elif \"on\" in participant_id:\n","            label = 2  # ON\n","        else:\n","            raise ValueError(f\"Rótulo desconhecido para o participante {participant_id}\")\n","\n","        X.append(segmentos)\n","        y.extend([label] * segmentos.shape[0])\n","\n","    X = np.concatenate(X, axis=0)  # Combinar todos os segmentos\n","    y = np.array(y)  # Criar array de rótulos\n","    return X, y\n","\n","# Preparar os dados segmentados\n","X, y = preparar_dados_segmentados(dados_segmentados)\n","\n","# Dividir os dados em 90% treino e 10% teste\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n","\n","# Exibir tamanhos dos conjuntos\n","print(f\"Treino: {X_train.shape}, Teste: {X_test.shape}\")\n","\n","# Converter para tensores PyTorch e transferir para o dispositivo\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n","\n","# Criar TensorDataset e DataLoader\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Exibir informações dos DataLoaders\n","print(f\"Número de batches - Treino: {len(train_loader)}, Teste: {len(test_loader)}\")"],"metadata":{"id":"H-4-NTjp6UYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modelo Transformer para classficação\n","\n"],"metadata":{"id":"HosaYsy06eeV"}},{"cell_type":"code","source":["\n","# Classe PositionalEncoding\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len):\n","        super(PositionalEncoding, self).__init__()\n","        self.encoding = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n","        self.encoding[:, 0::2] = torch.sin(position * div_term)\n","        self.encoding[:, 1::2] = torch.cos(position * div_term)\n","        self.encoding = self.encoding.unsqueeze(0)\n","\n","    def forward(self, x):\n","        if x.size(1) > self.encoding.size(1):\n","            raise ValueError(\n","                f\"Comprimento da entrada ({x.size(1)}) excede o máximo permitido ({self.encoding.size(1)}). \"\n","                \"Ajuste `max_len` na PositionalEncoding.\"\n","            )\n","        return x + self.encoding[:, :x.size(1), :].to(x.device)\n","\n","# Modelo Transformer para EEG\n","class TransformerEEG(nn.Module):\n","    def __init__(self, n_channels, n_classes, seq_len, d_model=128, nhead=8, num_layers=3, dim_feedforward=256, dropout=0.3):\n","        super(TransformerEEG, self).__init__()\n","        self.input_proj = nn.Linear(n_channels, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len=seq_len)\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","        self.fc = nn.Linear(d_model, n_classes)\n","\n","    def forward(self, x):\n","        x = self.input_proj(x.transpose(1, 2))  # Projeção dos canais\n","        x = self.positional_encoding(x)\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=1)  # Pooling global\n","        x = self.fc(x)\n","        return x\n","\n","# Configuração do modelo\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","seq_len = 1024\n","n_classes = 3\n","model = TransformerEEG(\n","    n_channels=32,\n","    n_classes=n_classes,\n","    seq_len=seq_len,\n","    d_model=128,\n","    nhead=8,\n","    num_layers=3,\n","    dim_feedforward=256,\n","    dropout=0.3\n",").to(device)\n","\n","# Função de perda e otimizador\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0003)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","\n","# Treinamento\n","n_epochs = 15\n","train_losses = []\n","\n","for epoch in range(n_epochs):\n","    model.train()\n","    train_loss = 0\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    train_losses.append(train_loss)\n","\n","    print(f\"Época {epoch + 1}/{n_epochs} - Loss Treino: {train_loss:.4f}\")\n","\n","# Avaliação no conjunto de teste\n","model.eval()\n","correct = 0\n","total = 0\n","y_pred = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in test_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        outputs = model(batch_X)\n","        _, predicted = torch.max(outputs, 1)\n","        y_pred.extend(predicted.cpu().numpy())\n","        y_true.extend(batch_y.cpu().numpy())\n","        total += batch_y.size(0)\n","        correct += (predicted == batch_y).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n","\n","# Relatório de classificação\n","print(\"\\nRelatório de Classificação:\")\n","print(classification_report(y_true, y_pred))"],"metadata":{"id":"mXQiecoK6eFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(1, len(train_losses) + 1), train_losses, label='Perda de Treinamento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Perda')\n","plt.title('Perda de Treinamento')\n","plt.legend()\n","plt.show()\n","\n"],"metadata":{"id":"CKnn0hE47Fxf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Validação do modelo"],"metadata":{"id":"Usvv_xxo7J3d"}},{"cell_type":"markdown","source":["#### Teste"],"metadata":{"id":"y8xB9W7z7SxD"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Avaliação no conjunto de teste\n","model.eval()\n","correct = 0\n","total = 0\n","y_pred = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in test_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        outputs = model(batch_X)\n","        _, predicted = torch.max(outputs, 1)\n","        y_pred.extend(predicted.cpu().numpy())\n","        y_true.extend(batch_y.cpu().numpy())\n","        total += batch_y.size(0)\n","        correct += (predicted == batch_y).sum().item()\n","\n","# Acurácia\n","accuracy = correct / total\n","print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n","\n","# Relatório de classificação\n","print(\"\\nRelatório de Classificação:\")\n","print(classification_report(y_true, y_pred))\n","\n","# Matriz de Confusão\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","\n","# Plotar a Matriz de Confusão\n","classes = np.unique(y_true)  # Nomes das classes\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\" Matriz de confusão \")\n","plt.show()\n"],"metadata":{"id":"EP2p_iDl7ItC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Treino"],"metadata":{"id":"BcEX6V6Y7YUN"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","\n","# Avaliação no conjunto de treinamento\n","model.eval()\n","correct = 0\n","total = 0\n","y_pred = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        outputs = model(batch_X)\n","        _, predicted = torch.max(outputs, 1)\n","        y_pred.extend(predicted.cpu().numpy())\n","        y_true.extend(batch_y.cpu().numpy())\n","        total += batch_y.size(0)\n","        correct += (predicted == batch_y).sum().item()\n","\n","# Acurácia no conjunto de treinamento\n","accuracy = correct / total\n","print(f\"Acurácia no conjunto de treinamento: {accuracy:.4f}\")\n","\n","# Relatório de classificação\n","print(\"\\nRelatório de Classificação no Conjunto de Treinamento:\")\n","print(classification_report(y_true, y_pred))\n","\n","# Matriz de Confusão\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# Plotar a Matriz de Confusão\n","classes = np.unique(y_true)  # Nomes das classes\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Matriz de Confusão no Conjunto de Treinamento\")\n","plt.show()"],"metadata":{"id":"8SRl4C0-7b_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Captum"],"metadata":{"id":"ASuAk2Fw7ib3"}},{"cell_type":"code","source":["\n","\n","# Certifique-se de que o modelo está em modo de avaliação\n","model.eval()\n","\n","# Função para calcular as importâncias com Integrated Gradients\n","def calcular_importancias_ig(model, X_test, y_test):\n","    ig = IntegratedGradients(model)\n","    all_importances = []\n","\n","    for i in range(X_test.shape[0]):\n","        input_tensor = X_test[i].unsqueeze(0)  # Adicionar dimensão de batch\n","        target = y_test[i].unsqueeze(0)  # Adicionar dimensão de batch\n","        attributions, _ = ig.attribute(input_tensor, target=target, return_convergence_delta=True)\n","        all_importances.append(attributions.squeeze(0).mean(dim=1).cpu().numpy())  # Média por canal\n","\n","    return np.array(all_importances)\n","\n","# Cálculo das importâncias\n","all_importances = calcular_importancias_ig(model, X_test_tensor, y_test_tensor)\n","\n","# Nomes dos canais\n","try:\n","    nomes_canais = raw.info['ch_names']\n","except NameError:\n","    nomes_canais = [\n","        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n","        'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz', 'Oz', 'FC1', 'FC2',\n","        'CP1', 'CP2', 'PO1', 'PO2', 'AFz', 'TP1', 'TP2', 'FT1', 'FT2',\n","        'FCz', 'CPz', 'POz'\n","    ]\n","\n","# Função para calcular a média das importâncias por condição\n","def separar_por_condicao(importancias, y_test, num_canais):\n","    medias_importancias = {'HC': np.zeros(num_canais),\n","                           'OFF': np.zeros(num_canais),\n","                           'ON': np.zeros(num_canais)}\n","\n","    contadores = {'HC': 0, 'OFF': 0, 'ON': 0}\n","\n","    for i, classe in enumerate(y_test):\n","        if classe == 0:  # HC\n","            medias_importancias['HC'] += importancias[i]\n","            contadores['HC'] += 1\n","        elif classe == 1:  # OFF\n","            medias_importancias['OFF'] += importancias[i]\n","            contadores['OFF'] += 1\n","        elif classe == 2:  # ON\n","            medias_importancias['ON'] += importancias[i]\n","            contadores['ON'] += 1\n","\n","    # Normalizar pelas contagens\n","    for key in medias_importancias:\n","        if contadores[key] > 0:\n","            medias_importancias[key] /= contadores[key]\n","\n","    return medias_importancias\n","\n","# Calcular as médias das importâncias por condição\n","medias_importancias = separar_por_condicao(all_importances, y_test_tensor.cpu().numpy(), num_canais=32)\n","\n","# Gerar gráficos com os nomes reais dos canais\n","for condicao, importancias in medias_importancias.items():\n","    plt.figure(figsize=(12, 6))\n","    plt.bar(nomes_canais, importancias)\n","    plt.title(f\"Importância dos Canais - Condição: {condicao}\")\n","    plt.xlabel(\"Canais\")\n","    plt.ylabel(\"Importância Média\")\n","    plt.xticks(rotation=45)\n","    plt.grid(axis='y')\n","    plt.tight_layout()\n","    plt.show()\n","\n"],"metadata":{"id":"3E5gma_Q7h_F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Mapas topográficos"],"metadata":{"id":"PlcbMZlD71mf"}},{"cell_type":"code","source":["\n","\n","# Criar o info com os nomes dos canais e localização\n","montage = mne.channels.make_standard_montage(\"standard_1020\")  # Alterar conforme necessário\n","info = mne.create_info(ch_names=nomes_canais, sfreq=256, ch_types=\"eeg\")  # Frequência de amostragem arbitrária\n","info.set_montage(montage)\n","\n","# Função para gerar mapas topográficos\n","def gerar_mapas_topograficos(importancias_por_condicao, nomes_canais, info):\n","    for condicao, importancias in importancias_por_condicao.items():\n","        # Mapear importâncias para os canais\n","        evoked = mne.EvokedArray(np.expand_dims(importancias, axis=1), info, tmin=0)  # tmin define o tempo inicial\n","\n","        # Plotar mapa topográfico\n","        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n","        mne.viz.plot_topomap(evoked.data[:, 0], evoked.info, axes=ax, cmap=\"viridis\", show=False)\n","        ax.set_title(f\"Mapa Topográfico - Condição: {condicao}\")\n","        plt.show()\n","\n","# Gerar mapas topográficos\n","gerar_mapas_topograficos(medias_importancias, nomes_canais, info)"],"metadata":{"id":"APHRl0qB7w8A"},"execution_count":null,"outputs":[]}]}